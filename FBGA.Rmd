---
title: "FBGA Analysis"
author: "EPatton"
date: "2023-01-06"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(lubridate)
#library(sf)
#library(mapview)
#library(RColorBrewer)
library(readr)
library(ggplot2)
#install.packages('Hmisc')
#install.packages('fBasics')
library(fBasics)
library(Hmisc)
library(trend)
#install.packages('EnvStats')
library(EnvStats)
```

# Project Goals

## Load and clean data for FBGA datasets

### Determine and capture missing data numbers (done)
### Create daily high temps and low temps for data set (done)
### Create sWBGT, if needed

## Trend Analysis

### Increase(decrease) in Red & Black Flag Days for record
### Mann Kendall for entire period daily temps

## Heat Wave Analysis
Heat waves = Red or Black Flag day (?)
### Number of 3+ days heat waves over each month and year
### Number of 5+ days heat waves over each month and year

#### Load Data Sets
```{r load data}
##load the data set, assign it a name, and save the new name
#KLSF_Raw <- KLSF_Observations
#write.csv(KLSF_Raw, "/Users/erikpatton/Library/Mobile Documents/com~apple~CloudDocs/Duke/Data_Dissertation/Raw Data/KLSF_Raw.csv")

KLSF <- read_csv("/Users/erikpatton/Library/Mobile Documents/com~apple~CloudDocs/Duke/Data_Dissertation/Raw Data/KLSF_Raw.csv")
#view(KLSF)
#str(KLSF)
#summary(KLSF)

##CREATE DATE/TIME COLUMN
KLSF <- KLSF %>%
  mutate('datetime' = make_datetime(year=Year, month = Month, day = Day, hour = Hour..UTC.))%>%
  mutate('date' = make_date(year=Year, month = Month, day = Day))
head(KLSF$datetime)

##CREATE CELCIUS COLUMNS, RENAME COLUMNS TO STANDARIZE
KLSF <- KLSF%>%
  mutate('Temp.C' = ((Temperature..F.-32)*(5/9)))%>%
  mutate('Dewpoint.Temp.C' = (Dewpoint.Temperature..F.-32)*(5/9))%>%
  mutate('Heat.Index.C'=((Heat.Index..F.-32)*(5/9)))%>%
  mutate('WBGT.C'=((Derived.Wet.Bulb.Globe.Temperature..F.-32)*(5/9)))%>%
  rename('Temp.F' = Temperature..F.)%>%
  rename('Dewpoint.Temp.F'=Dewpoint.Temperature..F.)%>%
  rename('Heat.Index.F'=Heat.Index..F.)%>%
  rename("WBGT.F"=Derived.Wet.Bulb.Globe.Temperature..F.)
```
```{r CREATE SINGLE DAY MAX or MIN TEMPS}
#Create single day high temp
KLSF_DAILY_HIGH.C <- KLSF%>%
  group_by(date)%>%
  dplyr::summarise(daily_high = max(Temp.C))%>%
  as.data.frame()
#Create single day low temp
KLSF_DAILY_LOW.C <- KLSF%>%
  group_by(date)%>%
  dplyr::summarise(daily_LOW = min(Temp.C))%>%
  as.data.frame()
#Create single day high WBGT temp
KLSF_DAILY_HIGH_WBGT.C <- KLSF%>%
  group_by(date)%>%
  dplyr::summarise(daily_high_WBGT = max(WBGT.C))%>%
  as.data.frame()
#Create single day low WBGT temp
```
#### Load Data Sets - KCSG - ALTERNATE SITE
```{r load data}
##load the data set, assign it a name, and save the new name
#KCSG_Raw <- KCSG_Observations
#write.csv(KCSG_Raw, "/Users/erikpatton/Library/Mobile Documents/com~apple~CloudDocs/Duke/Data_Dissertation/Raw Data/KCSG_Raw.csv")

KCSG <- read_csv("/Users/erikpatton/Library/Mobile Documents/com~apple~CloudDocs/Duke/Data_Dissertation/Raw Data/KCSG_Raw.csv")
#view(KCSG)
#str(KCSG)
#summary(KCSG)

##CREATE DATE/TIME COLUMN
KCSG <- KCSG %>%
  mutate('datetime' = make_datetime(year=Year, month = Month, day = Day, hour = Hour..UTC.))%>%
  mutate('date' = make_date(year=Year, month = Month, day = Day))
head(KCSG$datetime)

##CREATE CELCIUS COLUMNS, RENAME COLUMNS TO STANDARIZE
KCSG <- KCSG%>%
  mutate('Temp.C' = ((Temperature..F.-32)*(5/9)))%>%
  mutate('Dewpoint.Temp.C' = (Dewpoint.Temperature..F.-32)*(5/9))%>%
  mutate('Heat.Index.C'=((Heat.Index..F.-32)*(5/9)))%>%
  mutate('WBGT.C'=((Derived.Wet.Bulb.Globe.Temperature..F.-32)*(5/9)))%>%
  rename('Temp.F' = Temperature..F.)%>%
  rename('Dewpoint.Temp.F'=Dewpoint.Temperature..F.)%>%
  rename('Heat.Index.F'=Heat.Index..F.)%>%
  rename("WBGT.F"=Derived.Wet.Bulb.Globe.Temperature..F.)
```
```{r CREATE SINGLE DAY MAX or MIN TEMPS ALT SITE KCSG}
KCSG_DAILY_HIGH.C <- KCSG%>%
  group_by(date)%>%
  dplyr::summarise(daily_high = max(Temp.C))%>%
  as.data.frame()

KCSG_DAILY_LOW.C <- KCSG%>%
  group_by(date)%>%
  dplyr::summarise(daily_LOW = min(Temp.C))%>%
  as.data.frame()

KCSG_DAILY_HIGH_WBGT.C <- KCSG%>%
  group_by(date)%>%
  dplyr::summarise(daily_high_WBGT = max(WBGT.C))%>%
  as.data.frame()

KCSG_DAILY_LOW_WBGT.C <- KCSG%>%
  group_by(date)%>%
  dplyr::summarise(daily_LOW_WBGT = min(WBGT.C))%>%
  as.data.frame()
```

#### Create an initial plot to visualize missing data 
```{r}
KLSF_DAILY_HIGH_PLOT.C <- ggplot(KLSF_DAILY_HIGH.C, aes(x = date, y=daily_high))+
  geom_line()+
  geom_smooth(method=lm, col='red')
print(KLSF_DAILY_HIGH_PLOT.C)
```
#### Create an initial plot to visualize missing data - ALT SITE - KCSG
```{r}
KCSG_DAILY_HIGH_PLOT.C <- ggplot(KCSG_DAILY_HIGH.C, aes(x = date, y=daily_high))+
  geom_line()+
  geom_smooth(method=lm, col='red')
print(KCSG_DAILY_HIGH_PLOT.C)
```




#### LOAD HEAT CATAGORY TEMPERATURE THRESHOLDS
```{r TEMPERATURE THRESHOLDS}
##Create the heat catagory data frame for reference
Flag_Color <- c("Green","Yellow","Red","Black")
Category_Temp_Min.F <- c(82,85,88,90)
Category_Temp_Max.F <- c(84.999,87.999,89.999,104)
Heat_Categories <- cbind(Flag_Color,Category_Temp_Min.F,Category_Temp_Max.F)
Heat_Categories <- as.data.frame(Heat_Categories)
##recast the vector as an integer to get the mutate code to work
Heat_Categories$Category_Temp_Min.F <- as.integer(Heat_Categories$Category_Temp_Min.F)
Heat_Categories$Category_Temp_Max.F <- as.integer(Heat_Categories$Category_Temp_Max.F)
##Create degree Celsius columns
Heat_Categories <- Heat_Categories%>%
  mutate(Category_Temp_Min.C = (Category_Temp_Min.F - 32)*(5/9))%>%
  mutate(Category_Temp_Max.C = (Category_Temp_Max.F-32)*(5/9))

#view(Heat_Categories)
```

#### Start Red and Black Flag Day Analysis
```{r}
##Filter for all days in 'RED' or 'BLACK' heat category
FBGA_WBGT_Filtered <- KLSF%>%
  filter(KLSF$WBGT.F >= Heat_Categories$Category_Temp_Min.F[3])%>%
  drop_na(WBGT.F)
#view(FBGA_WBGT_Filtered)
#summary(FBGA_WBGT_Filtered$WBGT.F)

##visualize the days above RED and BLACK heat cat
KLSF_REDorBLACK_plot <- ggplot(FBGA_WBGT_Filtered, aes(x = date, y=WBGT.F))+
  geom_line()+
  geom_point()
#print(KLSF_REDorBLACK_plot)
```
#### Start Red and Black Flag Day Analysis - ALT SITE - KCSG
```{r}
##Filter for all days in 'RED' or 'BLACK' heat category KCSG SITE
FBGA.KCSG_WBGT_Filtered <- KCSG%>%
  filter(KCSG$WBGT.F >= Heat_Categories$Category_Temp_Min.F[3])%>%
  drop_na(WBGT.F)
#view(FBGA_WBGT_Filtered)
#summary(FBGA.KCSG_WBGT_Filtered$WBGT.F)

##visualize the days above RED and BLACK heat cat KCSG SITE
KCSG_REDorBLACK_plot <- ggplot(FBGA.KCSG_WBGT_Filtered, aes(x = date, y=WBGT.F))+
  geom_line()+
  geom_point()
#print(KCSG_REDorBLACK_plot)

```
#### Group by year, count and  plot days above RED and above BLACK
```{r}
##group the data by year to do a trend analysis over the years - from 1973 to 2022
##returns number of hours per year at or above RED
##Filter for hours at RED or above
FBGA_WBGT_REDorABOVE_Hourly_byYear <- KLSF%>%
  filter(date>='1973-01-01')%>%
  subset(WBGT.F>=Heat_Categories$Category_Temp_Min.F[3])%>%
  group_by(Year)%>%
  count(Year)%>%
  rename(Hours_Above_Red = n)
#view(FBGA_WBGT_REDorABOVE_Hourly_byYear)
##Plots hours Red or Above
KLSF_Hours_REDorABOVE_peryear_plot <- ggplot(FBGA_WBGT_REDorABOVE_Hourly_byYear, aes(x = Year, y=Hours_Above_Red))+
  geom_line()+
  geom_point()
print(KLSF_Hours_REDorABOVE_peryear_plot)

##Filter for hours BLACK
FBGA_Hours_BLACK_byYear <- KLSF%>%
  filter(date>='1973-01-01')%>%
  subset(WBGT.F>=Heat_Categories$Category_Temp_Min.F[4])%>%
  group_by(Year)%>%
  count(Year)%>%
  rename(Hours_Above_Black = n)
#view(FBGA_Hours_BLACK_byYear)
##Plot hours in Black conditions
KLSF_Hours_Black_peryear_plot <- ggplot(FBGA_Hours_BLACK_byYear, aes(x = Year, y=Hours_Above_Black))+
  geom_line()+
  geom_point()
#print(KLSF_Hours_Black_peryear_plot)
```
#### Group by year, count and  plot days above RED and above BLACK - ALT SITE - KCSG
```{r}
##group the data by year to do a trend analysis over the years - from 1973 to 2022
##returns number of hours per year at or above RED
##Filter for hours at RED or above
FBGA.KCSG_WBGT_REDorABOVE_Hourly_byYear <- KCSG%>%
  filter(date>='1973-01-01')%>%
  subset(WBGT.F>=Heat_Categories$Category_Temp_Min.F[3])%>%
  group_by(Year)%>%
  count(Year)%>%
  rename(Hours_Above_Red = n)
#view(FBGA.KCSG_WBGT_REDorABOVE_Hourly_byYear)
##Plots hours Red or Above
KCSG_Hours_REDorABOVE_peryear_plot <- ggplot(FBGA.KCSG_WBGT_REDorABOVE_Hourly_byYear, aes(x = Year, y=Hours_Above_Red))+
  geom_line()+
  geom_point()
#print(KCSG_Hours_REDorABOVE_peryear_plot)

##Filter for hours BLACK
FBGA.KCSG_Hours_BLACK_byYear <- KCSG%>%
  filter(date>='1973-01-01')%>%
  subset(WBGT.F>=Heat_Categories$Category_Temp_Min.F[4])%>%
  group_by(Year)%>%
  count(Year)%>%
  rename(Hours_Above_Black = n)
#view(FBGA.KCSG_Hours_BLACK_byYear)
##Plot hours in Black conditions
KCSG_Hours_Black_peryear_plot <- ggplot(FBGA.KCSG_Hours_BLACK_byYear, aes(x = Year, y=Hours_Above_Black))+
  geom_line()+
  geom_point()
#print(KCSG_Hours_Black_peryear_plot)
```
#### COMBINED THE TWO FBGA PLOTS
```{r COMBINE THE TWO PLOTS}
FBGA_Combined <- full_join(FBGA_WBGT_REDorABOVE_Hourly_byYear,FBGA.KCSG_WBGT_REDorABOVE_Hourly_byYear, by='Year')

FBGA_Combined <- FBGA_Combined%>%
  rename(KLSF_RedorAbove_Hourly=Hours_Above_Red.x)%>%
  rename(KCSG_RedorAbove_Hourly=Hours_Above_Red.y)
#view(FBGA_Combined)

##Create a merged BLACK FLAG data frame
FBGA_Combined_Black_hourly <- full_join(FBGA_Hours_BLACK_byYear,FBGA.KCSG_Hours_BLACK_byYear, by='Year')%>%
  rename(KLSF_Black_Hours = Hours_Above_Black.x)%>%
  rename(KCSG_Black_Hours = Hours_Above_Black.y)
#  view(FBGA_Combined_Black_hourly)  


FBGA_Combined_plot <- ggplot(FBGA_Combined,aes(x=Year))+
  geom_line(aes(y=KLSF_RedorAbove_Hourly, col='blue'))+
  geom_smooth(aes(y=KLSF_RedorAbove_Hourly),color='blue')+
  geom_line(aes(y=KCSG_RedorAbove_Hourly, col='red'))+
  geom_smooth(aes(y=KCSG_RedorAbove_Hourly),color='red')+
  scale_color_manual(name='Location', breaks=c('Lawson AAF','Columbus Airport'), values=c('Lawson AAF'='blue','Columbus Airport'='red'))
print(FBGA_Combined_plot)

FBGA_Combined_Black_plot <- ggplot(FBGA_Combined_Black_hourly,aes(x=Year))+
  geom_line(aes(y=KLSF_Black_Hours, col='blue'))+
  geom_smooth(aes(y=KLSF_Black_Hours),color='blue')+
  geom_line(aes(y=KCSG_Black_Hours, col='red'))+
  geom_smooth(aes(y=KCSG_Black_Hours),color='red')+
  scale_color_manual(name='Location', breaks=c('Lawson AAF','Columbus Airport'), values=c('Lawson AAF'='blue','Columbus Airport'='red'))
print(FBGA_Combined_Black_plot)
```

#### STATISTICS AND CORRELATION BETWEEN THE TWO SITES - VALIDATE THEY BOTH ARE SIMILAR
```{r Highs - correlation between sites}
##CONDUCT A CORRELATION TEST BETWEEN THE TWO SITES TO SEE IF THEY MOVE IN THE SAME DIRECTION (AT LEAST STATISTICALLY)
##IF THEY DO, WE CAN SAY THAT THE TWO SITES ARE SHOWING THE SAME GENERAL CLIMATE TRENDS ACROSS YEARS
##NULL HYPOTHESIS IS THEY DO NOT MOVE IN THE SAME DIRECTION, AND THEREFORE WE HAVE LOWER CONFIDENCE IN USING THEM

##Essentially checking that similar sites near each other are legitimate and not contradictory

##Describe the data frame
lapply(FBGA_Combined,Hmisc::describe)

RedorAbove.regression <- lm(FBGA_Combined$KLSF_RedorAbove_Hourly~FBGA_Combined$KCSG_RedorAbove_Hourly)
summary(RedorAbove.regression)
cor.test(FBGA_Combined$KLSF_RedorAbove_Hourly,FBGA_Combined$KCSG_RedorAbove_Hourly)

##The graphs below can help check the fit of the linear model PEARSON'S
par(mfrow = c(2,2), mar=c(4,4,4,4))
plot(RedorAbove.regression)
par(mfrow = c(1,1))

##CHECK FOR NORMAL DISTRIBUTION TO THE POINTS
##Shapiro test, if P>0.05, then it IS normally distributed. In this case, hourly summary of KCSG is not normally distributed.
shapiro.test(FBGA_Combined$KLSF_RedorAbove_Hourly)
shapiro.test(FBGA_Combined$KCSG_RedorAbove_Hourly)
##Not normally distributed, so should not sure Pearson's correlation tests

FBGA_Combined%>%select(.,KLSF_RedorAbove_Hourly,KCSG_RedorAbove_Hourly)%>%map(~fBasics::dagoTest(.))
##Omnibus test <0.05 would indicate that the set is NOT normally distributed.

##USE KENDALL RANK CORRELATION TEST - can be used if not from normal distribution
cor.test(FBGA_Combined$KLSF_RedorAbove_Hourly,FBGA_Combined$KCSG_RedorAbove_Hourly,method="kendall")
##Shows positive correlation between the 2 sites (tau=0.279) and p-value < 0.05 (0.004) ; implies correlation

##USE SPEARMAN RANK CORRELATION COEFFICIENT - can be used if data is not norma;
cor.test(FBGA_Combined$KLSF_RedorAbove_Hourly,FBGA_Combined$KCSG_RedorAbove_Hourly,method="spearman")
##Shows rho = 0.416 and p-value <0.05 ; implies correlation

##All tests return positive correlation and low p-values, including tests robust to non-normal 
```

####TIME SERIES ANALYSIS ON THE DATASET
```{r Highs and Lows time series KLSF}
##LOOK FOR NAS OR MISSING DATA, INTERPOLATE WITH BEFORE AND AFTER VALUES

##High Temp
#summary(KLSF_DAILY_HIGH.C)
KLSF_Daily_High.C_Clean <- KLSF_DAILY_HIGH.C%>%
  mutate(High.C_Clean = zoo::na.approx(KLSF_DAILY_HIGH.C$daily_high))%>%
  select(date,High.C_Clean)%>%
  filter(date>='1973-01-01')
#summary(KLSF_Daily_High.C_Clean)
##No more NAs

KLSF_Daily_High.TS <- ts(KLSF_Daily_High.C_Clean$High.C_Clean, start = c(1973,01,01),frequency=365)
KLSF_Daily_High.decomp <- stl(KLSF_Daily_High.TS,s.window="periodic")
plot(KLSF_Daily_High.decomp)
KLSF_Daily_High_Trend <- Kendall::SeasonalMannKendall(KLSF_Daily_High.TS)
summary(KLSF_Daily_High_Trend)
##This returns a very small p=value, also a small tau, so we can state the trend is STRONGLY statistically significant even though the magnitude of the temperature increase is small (the tau value).

##WBGT
#summary(KLSF_DAILY_HIGH_WBGT.C)
KLSF_Daily_High_WBGT.C_Clean <- KLSF_DAILY_HIGH_WBGT.C%>%
  filter(date>='1973-01-01')%>%
  mutate(WBGT.C_Clean = zoo::na.approx(KLSF_DAILY_HIGH_WBGT.C$daily_high_WBGT))%>%
  select(date,WBGT.C_Clean)
#summary(KLSF_Daily_High_WBGT.C_Clean)
##No more NAs

##Temp Trend using Mann-Kendall Seasonal Analysis
KLSF_Daily_High_WBGT.TS <- ts(KLSF_Daily_High_WBGT.C_Clean$WBGT.C_Clean, start = c(1973,01,01),frequency=365)
KLSF_Daily_High_WBGT.decomp <- stl(KLSF_Daily_High_WBGT.TS,s.window="periodic")
plot(KLSF_Daily_High_WBGT.decomp)
KLSF_Daily_High_WBGT_Trend <- Kendall::SeasonalMannKendall(KLSF_Daily_High_WBGT.TS)
summary(KLSF_Daily_High_WBGT_Trend)
##This returns a very small p=value, also a small tau, so we can state the trend is STRONGLY statistically significant even though the magnitude of the temperature increase is small (the tau value).

##Low Temp
#summary(KLSF_DAILY_HIGH.C)
KLSF_Daily_LOW.C_Clean <- KLSF_DAILY_LOW.C%>%
  mutate(LOW.C_Clean = zoo::na.approx(KLSF_DAILY_LOW.C$daily_LOW))%>%
  select(date,LOW.C_Clean)%>%
  filter(date>='1973-01-01')
#summary(KLSF_Daily_LOW.C_Clean)
##No more NAs

KLSF_Daily_LOW.TS <- ts(KLSF_Daily_LOW.C_Clean$LOW.C_Clean, start = c(1973,01,01),frequency=365)
KLSF_Daily_LOW.decomp <- stl(KLSF_Daily_LOW.TS,s.window="periodic")
plot(KLSF_Daily_LOW.decomp)
KLSF_Daily_LOW_Trend <- Kendall::SeasonalMannKendall(KLSF_Daily_LOW.TS)
summary(KLSF_Daily_LOW_Trend)
##This returns a very small p=value, also a small tau, so we can state the trend is STRONGLY statistically significant even though the magnitude of the temperature increase is small (the tau value).
```
####TIME SERIES ANALYSIS ON THE DATASET - ALT SITE - KCSG
```{r Highs analysis KCSG}
##LOOK FOR NAS OR MISSING DATA, INTERPOLATE WITH BEFORE AND AFTER VALUES - KCSG

##High Temp
#summary(KCSG_DAILY_HIGH.C)
KCSG_Daily_High.C_Clean <- KCSG_DAILY_HIGH.C%>%
  mutate(High.C_Clean = zoo::na.approx(KCSG_DAILY_HIGH.C$daily_high))%>%
  select(date,High.C_Clean)%>%
  filter(date>='1973-01-01')
#summary(KCSG_Daily_High.C_Clean)
##No more NAs

KCSG_Daily_High.TS <- ts(KCSG_Daily_High.C_Clean$High.C_Clean, start = c(1973,01,01),frequency=365)
KCSG_Daily_High.decomp <- stl(KCSG_Daily_High.TS,s.window="periodic")
plot(KCSG_Daily_High.decomp)
KCSG_Daily_High_Trend <- Kendall::SeasonalMannKendall(KCSG_Daily_High.TS)
summary(KCSG_Daily_High_Trend)
##This returns a very small p=value, also a small tau, so we can state the trend is STRONGLY statistically significant even though the magnitude of the temperature increase is small (the tau value).

##WBGT - KCSG
#summary(KCSG_DAILY_HIGH_WBGT.C)
KCSG_Daily_High_WBGT.C_Clean <- KCSG_DAILY_HIGH_WBGT.C%>%
  mutate(WBGT.C_Clean = zoo::na.approx(KCSG_DAILY_HIGH_WBGT.C$daily_high_WBGT))%>%
  select(date,WBGT.C_Clean)%>%
  filter(date>='1973-01-01')
#summary(KCSG_Daily_High_WBGT.C_Clean)
##No more NAs

##Temp Trend using Mann-Kendall Seasonal Analysis - KCSG
KCSG_Daily_High_WBGT.TS <- ts(KCSG_Daily_High_WBGT.C_Clean$WBGT.C_Clean, start = c(1973,01,01),frequency=365)
KCSG_Daily_High_WBGT.decomp <- stl(KCSG_Daily_High_WBGT.TS,s.window="periodic")
plot(KCSG_Daily_High_WBGT.decomp)
KCSG_Daily_High_WBGT_Trend <- Kendall::SeasonalMannKendall(KCSG_Daily_High_WBGT.TS)
summary(KCSG_Daily_High_WBGT_Trend)
##This returns a very small p=value, also a small tau, so we can state the trend is STRONGLY statistically significant even though the magnitude of the temperature increase is small (the tau value).

##Low Temp
#summary(KCSG_DAILY_HIGH.C)
KCSG_Daily_LOW.C_Clean <- KCSG_DAILY_LOW.C%>%
  mutate(LOW.C_Clean = zoo::na.approx(KCSG_DAILY_LOW.C$daily_LOW))%>%
  select(date,LOW.C_Clean)%>%
  filter(date>='1973-01-01')
#summary(KCSG_Daily_LOW.C_Clean)
##No more NAs

KCSG_Daily_LOW.TS <- ts(KCSG_Daily_LOW.C_Clean$LOW.C_Clean, start = c(1973,01,01),frequency=365)
KCSG_Daily_LOW.decomp <- stl(KCSG_Daily_LOW.TS,s.window="periodic")
plot(KCSG_Daily_LOW.decomp)
KCSG_Daily_LOW_Trend <- Kendall::SeasonalMannKendall(KCSG_Daily_LOW.TS)
summary(KCSG_Daily_LOW_Trend)
##This returns a very small p=value, also a small tau, so we can state the trend is STRONGLY statistically significant even though the magnitude of the temperature increase is small (the tau value).
```

#### RUN THE PETTITT TEST TO SEE IF THERE IS A SPECIFIC YEAR THAT THE TREND 'TOOK OFF'
```{r Highs Pettitt KLSF and KCSG}
##Run the test of high temp TS
pettitt.test(KLSF_Daily_High.TS)

#find the date associated with the output 'time K 13497
KLSF_Daily_High.C_Clean[13497,]
#Trend change point in March 31st, 2010


##Run the test on WBGT TS
pettitt.test(KLSF_Daily_High_WBGT.TS)
#p-value is small, so there is a statistically significant point

#find the date associated with the output 'time K 11708
KLSF_Daily_High_WBGT.C_Clean[11708,]
#Trend change point in May 7th, 2005


##Run the test of high temp TS on ALT SITE KCSG
pettitt.test(KCSG_Daily_High.TS)

#find the date associated with the output 'time K 13594'
KCSG_Daily_High.C_Clean[13594,]
#Trend change point in March 31st, 2010 SAME AS KSLF DATA SET

##Run the test on WBGT TS
pettitt.test(KCSG_Daily_High_WBGT.TS)
#p-value is small, so there is a statistically significant point

#find the date associated with the output 'time K 13623
KCSG_Daily_High_WBGT.C_Clean[13623,]
#Trend change point in April 29, 2010
```

#### WHAT IS INCREASING AT A FASTER RATE - TEMPERATURE OR WBGT?
```{r Highs Analysis KLSF}
##MANUALLY RUN THE MANN KENDALL TEST - HIGH TEMPERATURE - MAX DAILY HIGH
#Set up month and year columns
KLSF_Daily_High.C_Clean$month <- month(ymd(KLSF_Daily_High.C_Clean$date))
KLSF_Daily_High.C_Clean$year <- year(ymd(KLSF_Daily_High.C_Clean$date))

KLSF_Daily_High.C_MannKendall <- kendallSeasonalTrendTest(High.C_Clean ~ month+year, data=KLSF_Daily_High.C_Clean)
KLSF_Daily_High.C_MannKendall$estimate

##MANUALLY RUN THE MANN KENDALL TEST - WBGT TEMPERATURE - MAX DAILY HIGH
#Set up month and year columns
KLSF_Daily_High_WBGT.C_Clean$month <- month(ymd(KLSF_Daily_High_WBGT.C_Clean$date))
KLSF_Daily_High_WBGT.C_Clean$year <- year(ymd(KLSF_Daily_High_WBGT.C_Clean$date))

KLSF_Daily_High_WBGT.C_MannKendall <- kendallSeasonalTrendTest(WBGT.C_Clean ~ month+year, data=KLSF_Daily_High_WBGT.C_Clean)
#return just tau, slope, and intercept
KLSF_Daily_High_WBGT.C_MannKendall$estimate
```
According to the slope, the High Temperature is increasing at a rate of 0.008230453 over the 1973-2022 data period. That is an increase of 0.428 degrees C (or about 0.77 degrees F). NOTE: This was run for the Max Daily High temperatures.
```{r Lows Analysis KLSF}}
##MANUALLY RUN THE MANN KENDALL TEST - HIGH TEMPERATURE - MAX DAILY HIGH
#Set up month and year columns
KLSF_Daily_LOW.C_Clean$month <- month(ymd(KLSF_Daily_LOW.C_Clean$date))
KLSF_Daily_LOW.C_Clean$year <- year(ymd(KLSF_Daily_LOW.C_Clean$date))

KLSF_Daily_LOW.C_MannKendall <- kendallSeasonalTrendTest(LOW.C_Clean ~ month+year, data=KLSF_Daily_LOW.C_Clean)
KLSF_Daily_LOW.C_MannKendall$estimate
```
##### The above minimum for KLSF does not appear to be working correctly - there is a 0.00 slope for any change in the minimum temperature. While possible, it seems more likely that something is not fit correctly (the mann-kendall from above gives a very strong correlation between temperature and date; unsure why this method does not provide the slope of that correlation.)
```{r Visualize the low C at KLSF to determine why no trend is occuring}
#ggplot(KLSF_Daily_LOW.C_Clean,aes(x=date,y=LOW.C_Clean))+
#  geom_point(size=0.5)+
#  geom_smooth(method="lm", formula = y~x)+
#  geom_text(data = KLSF_Daily_LOW.C_Clean, aes(x = date, y = LOW.C_Clean))

#summary(lm(LOW.C_Clean~date,data = KLSF_Daily_LOW.C_Clean))
#summary(lm(LOW.C_Clean~date,data = KCSG_Daily_LOW.C_Clean))
```

#### WHAT IS INCREASING AT A FASTER RATE - TEMPERATURE OR WBGT? - ALT SITE KCSG
```{r Highs analysis KCSG}
##MANUALLY RUN THE MANN KENDALL TEST - HIGH TEMPERATURE - MAX DAILY HIGH - ALT SITE KCSG
#Set up month and year columns
KCSG_Daily_High.C_Clean$month <- month(ymd(KCSG_Daily_High.C_Clean$date))
KCSG_Daily_High.C_Clean$year <- year(ymd(KCSG_Daily_High.C_Clean$date))

KCSG_Daily_High.C_MannKendall <- kendallSeasonalTrendTest(High.C_Clean ~ month+year, data=KCSG_Daily_High.C_Clean)
KCSG_Daily_High.C_MannKendall$estimate

##MANUALLY RUN THE MANN KENDALL TEST - WBGT TEMPERATURE - MAX DAILY HIGH - ALT SITE KCSG
#Set up month and year columns
KCSG_Daily_High_WBGT.C_Clean$month <- month(ymd(KCSG_Daily_High_WBGT.C_Clean$date))
KCSG_Daily_High_WBGT.C_Clean$year <- year(ymd(KCSG_Daily_High_WBGT.C_Clean$date))

KCSG_Daily_High_WBGT.C_MannKendall <- kendallSeasonalTrendTest(WBGT.C_Clean ~ month+year, data=KCSG_Daily_High_WBGT.C_Clean)
#return just tau, slope, and intercept
KCSG_Daily_High_WBGT.C_MannKendall$estimate
```
This returns an increase of just over 1F for the high temperature time period studied (1.03986F) based on the slope of 0.011111. NOTE: Run just for max temperatures.
```{r LOWS analysis KCSG}
##MANUALLY RUN THE MANN KENDALL TEST - LOW TEMPERATURE - MIN DAILY LOW - ALT SITE KCSG
#Set up month and year columns
KCSG_Daily_LOW.C_Clean$month <- month(ymd(KCSG_Daily_LOW.C_Clean$date))
KCSG_Daily_LOW.C_Clean$year <- year(ymd(KCSG_Daily_LOW.C_Clean$date))

KCSG_Daily_LOW.C_MannKendall <- kendallSeasonalTrendTest(LOW.C_Clean ~ month+year, data=KCSG_Daily_LOW.C_Clean)
KCSG_Daily_LOW.C_MannKendall$estimate
```
Slope for increased temperature for minimum at KCSG is 0.02614379. This is 1.36C or 2.45F.




#### VALIDATE AND PLOT THAT TWO SAMPLE SITES FOLLOW REGIONAL TREND
```{r CREATE AND READ IN NOAA WEST CENTRAL GA DATA SET - DAILY HIGH TEMP}
#write_csv(NOAA_GA_WestCentral, "/Users/erikpatton/Library/Mobile Documents/com~apple~CloudDocs/Duke/Data_Dissertation/Raw Data/NOAA_GA_WestCentral.csv")
#write_csv(STATION_Missing.Years, "/Users/erikpatton/Library/Mobile Documents/com~apple~CloudDocs/Duke/Data_Dissertation/Raw Data/NOAA_GA_WestCentral_MissingYears.csv")
NOAA_Raw <- read.csv("/Users/erikpatton/Library/Mobile Documents/com~apple~CloudDocs/Duke/Data_Dissertation/Raw Data/NOAA_GA_WestCentral.csv")
NOAA_Raw_MissingYears <- read.csv("/Users/erikpatton/Library/Mobile Documents/com~apple~CloudDocs/Duke/Data_Dissertation/Raw Data/NOAA_GA_WestCentral_MissingYears.csv")
```

```{r WRANGLE NOAA WEST CENTRAL GA DATA}
##create a name for the full data set and bind the missing data piece(s)
NOAA_GA_WestCentral <- NOAA_Raw
NOAA_GA_WestCentral <- rbind(NOAA_GA_WestCentral, NOAA_Raw_MissingYears)
##select needed columns and remove duplicates
GA_NOAA_Wrangled <- NOAA_GA_WestCentral %>%
  select(NAME, DATE, TMAX)%>%
  distinct()%>%
  arrange(ymd(DATE))

GA_NOAA_Wrangled$DATE <- as_date(GA_NOAA_Wrangled$DATE)

GA_NOAA_Wrangled_Wide <- pivot_wider(GA_NOAA_Wrangled,names_from = NAME, values_from = TMAX)
#view(GA_NOAA_Wrangled_Wide)
```


```{r TRY AND GET AVERAGE HIGH TEMPARTURES PER DAY - THE AVERAGE FOR THE GEORGIA WEST CENTRAL REPORTING DISTRICT (i.e. where FBGA is located)}
##Create a new column with the average temperature of all stations that reported for that date
GA_NOAA_Wrangled_Wide$Row_AVG <- rowMeans(GA_NOAA_Wrangled_Wide[,2:141],na.rm=TRUE)

GA_NOAA_Wrangled_Wide <- GA_NOAA_Wrangled_Wide%>%
  select(DATE,Row_AVG)%>%
  mutate(Row_AVG.C = ((Row_AVG-32)*(5/9)))%>%
  rename(date=DATE)

#Join all three main data sets to the same NOAA data set (NOAA data set is most complete)
GA_NOAA_Wrangled_Wide <-  full_join(GA_NOAA_Wrangled_Wide,KLSF_Daily_High.C_Clean,by="date")
GA_NOAA_Wrangled_Wide <- GA_NOAA_Wrangled_Wide%>%
  select(date,Row_AVG.C,High.C_Clean)%>%
  rename(KLSF.C=High.C_Clean)
GA_NOAA_Wrangled_Wide <- full_join(GA_NOAA_Wrangled_Wide,KCSG_Daily_High.C_Clean,by="date")
GA_NOAA_Wrangled_Wide <- GA_NOAA_Wrangled_Wide%>%
  select(date,Row_AVG.C,KLSF.C,High.C_Clean)%>%
  rename(KCSG.C=High.C_Clean)
view(GA_NOAA_Wrangled_Wide)
```
```{r PLOT THE THREE DAILY HIGH TEMPERATURES}
GA_Daily_High.C <- GA_NOAA_Wrangled_Wide
GA_Daily_High.C.plot <- ggplot(GA_Daily_High.C, aes(x=date))+
  geom_line(aes(y=KLSF.C, color='blue'), size=0.2)+
  geom_line(aes(y=KCSG.C,color='red'),linewidth=0.2)+
  geom_line(aes(y=Row_AVG.C,color='white'),linewidth=0.2)
GA_Daily_High.C.plot

##SUBSECTION FOR LAST TEN YEARS FOR BETTER VISUAL ANALYSIS
GA_Daily_High.C._Last10Year <- GA_Daily_High.C%>%
  filter(date>="2012-01-01", date<="2018-01-01")
  
GA_Daily_High.C.plot_10Year <- ggplot(GA_Daily_High.C._Last10Year, aes(x=date))+
  geom_line(aes(y=KLSF.C, color='blue'), size=0.2)+
  geom_line(aes(y=KCSG.C,color='red'),linewidth=0.2)+
  geom_line(aes(y=Row_AVG.C,color='white'),linewidth=0.2)
GA_Daily_High.C.plot_10Year
```
#### HEAT WAVE ANALYSIS SECTION FROM HEAT WAVE PACKAGE
```{r SET UP THE HEAT WAVE DATA FRAME AND PACKAGE}
install.packages('heatwaveR')
library(heatwaveR)
library(ggpubr)
library(ggplot2)
#Work on heatwaveR package

#package needs a tmin and tmax column
##NOTE date column must be assigned name as 't'
KLSF_heatwave <- data.frame(t=KLSF_Daily_High.C_Clean$date, tMax=KLSF_Daily_High.C_Clean$High.C_Clean, tmin= KLSF_Daily_LOW.C_Clean$LOW.C_Clean)

tMax_clim <- ts2clm(data=KLSF_heatwave, y= tMax, climatologyPeriod = c("1973-01-01","2022-09-30"), pctile = 95)
tMin_exc <- exceedance(data = KLSF_heatwave, y = tmin, threshold = 20, minDuration = 3, maxGap = 1)$threshold

##NOTE you can probably substitute the 95% column for minumum temperatures against the fixed value of '20' used here.
```

```{r RUN THE HEAT WAVE PACKAGE I.E. DETECT EVENT}
# Note that because we calculated our 90th percentile threshold on a column named 'tMax' 
# and not the default column name 'temp', we must specify this below with 'y = tMax'
events <- detect_event(data = tMax_clim, y = tMax, # The 90th percentile threshold
                       threshClim2 = tMin_exc$exceedance) # The flat exceedance threshold
#events

#event_exc <- exceedance(data = tMax_clim, y = tMax, # The 90th percentile threshold
 #                      threshClim2 = tMin_exc$exceedance)


```

```{r CREATE PLOTS FROM THE WEBSITE CODE}
bubble_plot <- ggplot(data = events$event, aes(x = date_peak, y = intensity_max)) +
  geom_point(aes(size = intensity_cumulative), shape = 21, fill = "salmon", alpha = 0.8) +
  labs(x = NULL, y = "Maximum Intensity [°C] ", size = "Cumulative Intensity [°C x days]") +
  scale_size_continuous(range = c(1, 10), 
                        guide = guide_legend(title.position = "top", direction = "horizontal")) +
  theme_bw() +
  theme(legend.position = c(0.3, 0.12),
        legend.box.background = element_rect(colour = "black"))
#print(bubble_plot)

ggarrange(event_line(events, y = tMax, metric = "intensity_max"),
          event_line(events, y = tMax, metric = "intensity_max", category = T),
          lolli_plot(events),
          bubble_plot,
          ncol = 2, nrow = 2, align = "hv")
##The below is giving trouble and will need troubleshooting to figure out
#event_line(events, spread = 10, start_date = "1973-05-01", end_date="2000-12-31", category = TRUE)

```